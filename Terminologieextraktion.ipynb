{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Terminologieextraktion.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/DAAD-Training-2021/blob/main/Terminologieextraktion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdVOtsDlWDWX"
      },
      "source": [
        "# Navigating Google Colab notebooks: \n",
        "\n",
        "1. You can click the folder icon on the left to **see/upload/download files**\n",
        "2. There are two types of cells: **code and text**. \n",
        "3. You can **edit/change/update** any cell by clicking on it (the code runs in your own personal account on Google cloud, other participants work in their own spaces with the same downloaded code)\n",
        "4. You can **download/save a copy of your Notebook** or the Python file to your local computer or your Google Drive via the *File* menu\n",
        "5. To **run a code cell**, you can either click on the “run” icon to the left; or press *Ctr+Enter*\n",
        "6. To add a new code/text cell below the current cell, click on *+Text* or *+Code* buttons;\n",
        "7. To **convert between code and text**: \n",
        "- *“Control_m m”* will convert a code cell to a text cell. \n",
        "- *“Control_m y”* will convert a text cell to a code cell.\n",
        "8. Under *“Runtime > Change runtime type”* you can request a **CPU-only, or GPU or a TPU environment** (depending on the code you run: some Machine Learning packages require GPU for faster processing).\n",
        "9. The *Python notebook* is opened by default. **To create an *R notebook***, run https://colab.research.google.com/#create=true&language=r or https://colab.to/r ; you can check that you run R in *“Runtime > Change Runtime type”* (R or Python3 will the the choices); GPU and TPU will be available for R notebooks as well.\n",
        "10. Saving your work: go to *\"File > Save a copy in Drive\"*\n",
        "- For the excercises please run each cell in the order how they appear. \n",
        "- Some cells (for training neural networks or downloading large models) will run for about 10-15 min -- just grab a cup of coffee!\n",
        "- Experiment with your own examples\n",
        "- The environment will clear when you leave the Colab space, please make sure you save your changes on the Google Drive\n",
        "\n",
        "Handount: https://docs.google.com/document/d/1S2fPnFuv5tbLWsS2Wsr8HeZ9CUQZR4100npmSRXuip0/edit?usp=sharing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3ESYeTTldEK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aynNt2Gjjfl"
      },
      "source": [
        "## Try it out: convert this section to code and run it. It should print a message\n",
        "\n",
        "my_name = 'First Last'\n",
        "\n",
        "print(f'Hello from {my_name}!\\n')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtWZ1FuvlfLk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A04lacMKrNJe"
      },
      "source": [
        "# Downloading / uploading a text corpus\n",
        "\n",
        "## George Orwell, 1984 novel: \n",
        "https://heibox.uni-heidelberg.de/d/d65daff8341e467c82b1/\n",
        "\n",
        "(texts in en, de, fr, es, it. You can search for a freely-available text in your own language).\n",
        "\n",
        "## Wikipedia corpus\n",
        "This site contains plain text versions of the Wikipedia:\n",
        "https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-2735#\n",
        "\n",
        "You can download the version for your favourite language(s).\n",
        "\n",
        "1. Download the \"1984\" novel into your local drive\n",
        "2. Upload it onto the Colab file system:\n",
        "- *Files* button to the left \n",
        "- *Upload to Session storage* button\n",
        "3. Examine the file on Colab\n",
        "4. Write a command to download it onto your system automatically: tip -- google \"wget\" and use it in Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXKKCk4ow8fQ"
      },
      "source": [
        "# ArmenianWP\n",
        "!wget https://heibox.uni-heidelberg.de/f/206d85a0270943e4b87b/?dl=1\n",
        "# renaming file\n",
        "!mv index.html?dl=1 WPhy_vert.txt\n",
        "\n",
        "# Constitution Republic of Armenia\n",
        "!wget https://heibox.uni-heidelberg.de/f/bf54977b17604ec592cd/?dl=1\n",
        "# renaming file\n",
        "!mv index.html?dl=1 Const_RA_l.txt\n",
        "\n",
        "# Grundgesetz\n",
        "!wget https://heibox.uni-heidelberg.de/f/d6c5b31edc84422d9e14/?dl=1\n",
        "# renaming file\n",
        "!mv index.html?dl=1 GG_l.txt\n",
        "\n",
        "# Origin of the species\n",
        "!wget https://heibox.uni-heidelberg.de/f/befc6dbe718b4a37ba74/?dl=1\n",
        "# renaming file\n",
        "!mv index.html?dl=1 OOOS_l.txt\n",
        "\n",
        "# Europarl DE\n",
        "!wget https://heibox.uni-heidelberg.de/f/3ba6122e744e4b7f9c14/?dl=1\n",
        "# renaming file\n",
        "!mv index.html?dl=1 EP_DE_l.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeamIEr15Lev"
      },
      "source": [
        "#Terminologieextraktion\n",
        "import os, re, sys\n",
        "class clProcCorpus(object):\n",
        "  ''' we will read a text file and return a dictionary\n",
        "  this will be done on the line by line basis\n",
        "  The dictionary can be sorted later...\n",
        "  '''\n",
        "  # this is a class for processing a corpus\n",
        "\n",
        "  def __init__(self, FileIN):\n",
        "    self.DictFrq = {}\n",
        "    self.processCorpus(FileIN)\n",
        "\n",
        "  def processCorpus(self, FileIN):\n",
        "    LTerm = []\n",
        "    for Line in FileIN:\n",
        "      Line = Line.strip()\n",
        "      LLine = re.split('\\t', Line)\n",
        "      try:\n",
        "        Word = LLine[0]\n",
        "        PoS = LLine[1]\n",
        "        Lemma = LLine[2]\n",
        "      except:\n",
        "        Word = \"\"\n",
        "        PoS = \"\"\n",
        "        Lemma = \"\"\n",
        "      \n",
        "#Select the Tags for your langauge\n",
        "      #if re.match('N.*', PoS) or re.match('A.*', PoS): #Arm\n",
        "      if re.match('N.*', PoS) or re.match('ADJ.*', PoS): #DE\n",
        "      #if re.match('N.*', PoS) or re.match('J.*', PoS): #EN\n",
        "\n",
        "#Terms as Words or Lemmas\n",
        "        LTerm.append(Lemma)\n",
        "      else:\n",
        "        STerm = ' '.join(LTerm)\n",
        "        LTerm = []\n",
        "\n",
        "        try:\n",
        "            self.DictFrq[STerm] += 1\n",
        "        except:\n",
        "            self.DictFrq[STerm] = 1        \n",
        "\n",
        "    return\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnxocDPBMHcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d584ac6-5cea-48fd-ea4a-76706714c697"
      },
      "source": [
        "#FileIN = open('GG_l.txt', 'r')\n",
        "#FileOut = open('GG_term.txt', 'w')\n",
        "\n",
        "#FileIN = open('EP_DE_l.txt', 'r')\n",
        "#FileOut = open('EP_DE_term.txt', 'w')\n",
        "\n",
        "#FileIN = open('OOOS_l.txt', 'r')\n",
        "#FileOut = open('OOOS_term.txt', 'w')\n",
        "\n",
        "#FileIN = open('Const_RA_l.txt', 'r')\n",
        "#FileOut = open('Const_RA_term.txt', 'w')\n",
        "\n",
        "#FileIN = open('Const_RF_l.txt', 'r')\n",
        "#FileOut = open('Const_RF_term.txt', 'w')\n",
        "\n",
        "# Georgian Brown corpus (lemmatisiert)\n",
        "!wget https://heibox.uni-heidelberg.de/f/d306be8b559849e79826/?dl=1\n",
        "# renaming file\n",
        "!mv index.html?dl=1 ge_Brown_lem.txt\n",
        "\n",
        "\n",
        "\n",
        "#FileIN = open('WPhy_vert.txt', 'r')\n",
        "#FileOut = open('WPhy-terms.txt', 'w')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-01 11:08:44--  https://heibox.uni-heidelberg.de/f/d306be8b559849e79826/?dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/86b13802-0034-44e1-b27d-4dc23002612f/ge_Brown_lem.txt [following]\n",
            "--2021-09-01 11:08:44--  https://heibox.uni-heidelberg.de/seafhttp/files/86b13802-0034-44e1-b27d-4dc23002612f/ge_Brown_lem.txt\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17565804 (17M) [text/plain]\n",
            "Saving to: ‘index.html?dl=1’\n",
            "\n",
            "index.html?dl=1     100%[===================>]  16.75M  13.6MB/s    in 1.2s    \n",
            "\n",
            "2021-09-01 11:08:46 (13.6 MB/s) - ‘index.html?dl=1’ saved [17565804/17565804]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY0xMY9SMSEE"
      },
      "source": [
        "# save the frequency dictionary into file, by decreasing frequencies\n",
        "# FileOutput.write( str( DictionaryFrq ) + '\\n' )\n",
        "\n",
        "OCorpus = clProcCorpus(FileIN)\n",
        "DictionaryFrq = OCorpus.DictFrq\n",
        "\n",
        "\n",
        "for Word, Frq in sorted( DictionaryFrq.items() , key=lambda x: x[1], reverse=True):\n",
        "  if re.search(' ', Word):\n",
        "    FileOut.write(Word + '\\t' + str(Frq) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYKESFuT5L9L"
      },
      "source": [
        "## Tasks\n",
        "1. Examine the frequencies file; \n",
        "2. download it onto your local machine; \n",
        "3. Change the programme to create a frequency dictionary from another file / corpus / language\n",
        "4. Change the programme to preserve lower/upper-case letters; how would you print out only words with frequency >1 ?\n",
        "5. Run it again and compare the results (save the results in another file).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUPLnj8E5byZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFoclZ5sSuwR"
      },
      "source": [
        "# Foundations of Python:\n",
        "1. Variables\n",
        "\n",
        "2. Data types\n",
        "- integers, floating point numbers\n",
        "- strings\n",
        "- lists, tuples\n",
        "- dictionaries, multidimensional dictionaries\n",
        "- files\n",
        "\n",
        "3. Regular expressions\n",
        "- Match and search\n",
        "- Capturing expressions in context\n",
        "\n",
        "4. Control flow statements\n",
        "- if, elif, else\n",
        "- while, for\n",
        "- break, continue\n",
        "- range\n",
        "\n",
        "5. Functions\n",
        "- standard functions (e.g., sorted)\n",
        "- writing own functions\n",
        "\n",
        "6. Classes and objects\n",
        "- Object packages and libraries \n",
        "- Ideas of object-oriented programming\n",
        "\n",
        "7. Writing reusable code and using others' libraries\n",
        "- Principles of software engineering\n",
        "- Using objects for Machine Learning (tensorflow, pytorch), text processing (NLTK), data visualisation"
      ]
    }
  ]
}