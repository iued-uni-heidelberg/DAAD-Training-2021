{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Terminologieextraktion5KeynessScoresV01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCfd/pOWf38glgjyA4s8Yr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/DAAD-Training-2021/blob/main/Terminologieextraktion5KeynessScoresV01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LOKq_mm4pZp"
      },
      "source": [
        "# The analysis of keyness, which will be used in term extraction\n",
        "\n",
        "---\n",
        "We will also prepare the gold standard evaluation set for the project\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMDN0mCX4Yeo",
        "outputId": "6b867f94-4bea-42a9-f522-c60fa9b5df95"
      },
      "source": [
        "# Stage 0: Preparing Gold standard: Reading / extracting information from gold standard: creating a list of annotated terms\n",
        "!wget https://heibox.uni-heidelberg.de/f/ae1110c4f9ad42b9a3d5/?dl=1\n",
        "!mv index.html?dl=1 BGH1_s00Astghik.txt\n",
        "!wget https://heibox.uni-heidelberg.de/f/0c787f26123f49178639/?dl=1\n",
        "!mv index.html?dl=1 BGH1_s00Hayk.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-26 14:11:15--  https://heibox.uni-heidelberg.de/f/ae1110c4f9ad42b9a3d5/?dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/2f31b4c9-063e-4d88-b130-c556767489d5/BGH1_Astghik.txt [following]\n",
            "--2021-10-26 14:11:15--  https://heibox.uni-heidelberg.de/seafhttp/files/2f31b4c9-063e-4d88-b130-c556767489d5/BGH1_Astghik.txt\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 369792 (361K) [text/plain]\n",
            "Saving to: ‘index.html?dl=1’\n",
            "\n",
            "index.html?dl=1     100%[===================>] 361.12K   638KB/s    in 0.6s    \n",
            "\n",
            "2021-10-26 14:11:16 (638 KB/s) - ‘index.html?dl=1’ saved [369792/369792]\n",
            "\n",
            "--2021-10-26 14:11:17--  https://heibox.uni-heidelberg.de/f/0c787f26123f49178639/?dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/955bcdc0-dea7-44fa-b4ea-a1e48edd1714/BGH2_Hayk.txt [following]\n",
            "--2021-10-26 14:11:17--  https://heibox.uni-heidelberg.de/seafhttp/files/955bcdc0-dea7-44fa-b4ea-a1e48edd1714/BGH2_Hayk.txt\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 411864 (402K) [text/plain]\n",
            "Saving to: ‘index.html?dl=1’\n",
            "\n",
            "index.html?dl=1     100%[===================>] 402.21K   644KB/s    in 0.6s    \n",
            "\n",
            "2021-10-26 14:11:18 (644 KB/s) - ‘index.html?dl=1’ saved [411864/411864]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iks1ZFSk5DwF"
      },
      "source": [
        "!cat BGH1_s00Astghik.txt BGH1_s00Hayk.txt >BGH1_s00GoldStandard.txt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBBoefCq5ZRx"
      },
      "source": [
        "FInput = open('BGH1_s00GoldStandard.txt', 'r')\n",
        "FOutput = open('BGH1_s00GoldS_Terms.txt', 'w')\n",
        "# for statistical purposes - separately single and multiword terms\n",
        "FOutputDict1w = open('BGH1_s00GoldS_D1w.txt', 'w') # 1-word terms\n",
        "FOutputDict2w = open('BGH1_s00GoldS_D2w.txt', 'w') # 2-word terminological expressions\n",
        "FOutputDictMWE = open('BGH1_s00GoldS_DMWE.txt', 'w') # more than 2 words"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcHAXZKV5gBk"
      },
      "source": [
        "def printDictionary(DictionaryFrq, FOut, Rev = True):\n",
        "    for Word, Frq in sorted( DictionaryFrq.items() , key=lambda x: x[1], reverse=Rev):\n",
        "        FOut.write(Word + '\\t' + str(Frq) + '\\n')\n",
        "    return"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiQLaMV05gxN"
      },
      "source": [
        "import re, os, sys\n",
        "LGSTerms = [] # gold standard terms\n",
        "DGS1w = {} # dictionary of single words\n",
        "DGS2w = {} # dictionary of single words\n",
        "DGSMWE = {} # dictionary of mwes\n",
        "IGS1w = 0 # number of annotated tokens of single words\n",
        "IGS2w = 0\n",
        "IGSMWE = 0 # number of annotated tokens of multiwords\n",
        "for SLine in FInput:\n",
        "    LAnnotatedTermsInLine = re.findall('<<([^><]+)>>', SLine)\n",
        "    LGSTerms.extend(LAnnotatedTermsInLine)\n",
        "\n",
        "for GSTerm in LGSTerms:\n",
        "    GSTerm = GSTerm.strip()\n",
        "    GSTerm = re.sub(' +', ' ', GSTerm)\n",
        "    LGSTErms = re.split(' ', GSTerm)\n",
        "    if len(LGSTErms) > 2:\n",
        "        IGSMWE += 1\n",
        "        try: DGSMWE[GSTerm] += 1\n",
        "        except: DGSMWE[GSTerm] = 1\n",
        "    if len(LGSTErms) == 2:\n",
        "        IGS2w += 1\n",
        "        try: DGS2w[GSTerm] +=1\n",
        "        except: DGS2w[GSTerm] = 1\n",
        "    else:\n",
        "        IGS1w += 1\n",
        "        try: DGS1w[GSTerm] +=1\n",
        "        except: DGS1w[GSTerm] = 1\n",
        "\n",
        "    FOutput.write(GSTerm + '\\n')\n",
        "\n",
        "FOutputDictMWE.write('# Number of tokens: ' + str(IGSMWE) + '\\n')\n",
        "FOutputDict2w.write('# Number of tokens: ' + str(IGS2w) + '\\n')\n",
        "FOutputDict1w.write('# Number of tokens: ' + str(IGS1w) + '\\n')\n",
        "\n",
        "printDictionary(DGSMWE, FOutputDictMWE)\n",
        "printDictionary(DGS2w, FOutputDict2w)\n",
        "printDictionary(DGS1w, FOutputDict1w)\n",
        "\n",
        "FOutputDictMWE.flush()\n",
        "FOutputDictMWE.close()\n",
        "FOutputDict2w.flush()\n",
        "FOutputDict2w.close()\n",
        "FOutputDict1w.flush()\n",
        "FOutputDict1w.close()\n",
        "\n",
        "FOutput.flush()\n",
        "FOutput.close()\n",
        "\n",
        "FInput.close()"
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}