{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Terminologieextraktion9EvaluationKeyWordsV02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPiWq3oXJ2ci9oVHKYmzS5J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/DAAD-Training-2021/blob/main/Terminologieextraktion9EvaluationKeyWordsV02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x08Plvp9F_mA"
      },
      "source": [
        "# Stage 0: Some useful read/write and convert functions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsmKBqMgGWLf"
      },
      "source": [
        "# import useful libraries, files\n",
        "\n",
        "import re, os, sys"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ9Hkx0OGfCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "280d87c5-5ff2-4b57-a336-68289fb5adca"
      },
      "source": [
        "# file for recording results of different configurations\n",
        "# run this only once\n",
        "!rm AllTermExtractionResultsV01.txt\n",
        "!rm AllTermExtractionResultsV02.txt\n",
        "\n",
        "FOutResults1 = open('AllTermExtractionResultsV01.txt', 'a')\n",
        "FOutResults2 = open('AllTermExtractionResultsV02.txt', 'a')\n",
        "FOutResults1.write('Run\\tW1A\\tW1B\\tW1C\\tW1D\\tW1P\\tW1R\\tW2A\\tW2B\\tW2C\\tW2D\\tW2P\\tW2R\\tW3A\\tW3B\\tW3C\\tW3D\\tW3P\\tW3R\\tW4A\\tW4B\\tW4C\\tW4D\\tW4P\\tW4R\\n')\n",
        "FOutResults2.write('Run\\tW1P\\tW1R\\tW2P\\tW2R\\tW3P\\tW3R\\tW4P\\tW4R\\n') # only precision and recall figures\n",
        "FOutResults1.flush()\n",
        "FOutResults2.flush()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'AllTermExtractionResultsV01.txt': No such file or directory\n",
            "rm: cannot remove 'AllTermExtractionResultsV02.txt': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqvEq6IGGfv1"
      },
      "source": [
        "## to modify if necessary; however, we try to keep the code standard and parametrize as much as possible\n",
        "\n",
        "# useful functions\n",
        "# a useful function for recording / visualising current stage of dictionaries\n",
        "def printDictionary(DictionaryFrq, FOut, K = 1, Rev = True): # printing a dictionary: by values or alphabetically\n",
        "    for Word, Frq in sorted( DictionaryFrq.items() , key=lambda x: x[K], reverse=Rev):\n",
        "        FOut.write(Word + '\\t' + str(Frq) + '\\n')\n",
        "    FOut.flush()\n",
        "    return\n",
        "\n",
        "# another useful function to just read and return a 2-field dictionary, eg., frequency or keyness\n",
        "def readDictionary(FIN, SkipComments = True, Caps=False):\n",
        "    DScoresLarge = {} # keywords - scores\n",
        "    for Line in FIN:\n",
        "        if SkipComments and re.match('#', Line): \n",
        "            continue\n",
        "        Line = Line.strip()\n",
        "        if Caps: \n",
        "            Line = Line.upper() # convert to upper case\n",
        "        LFieldsKW = re.split('\\t', Line)\n",
        "        SWord = LFieldsKW[0]\n",
        "        AKScore = float(LFieldsKW[1])\n",
        "        DScoresLarge[SWord] = AKScore   \n",
        "    return DScoresLarge\n",
        "\n",
        "# another possibly useful function: convert dictionary values to ranks (frequency, keyness weights, etc.)\n",
        "# for understanding how far down the list the item has been found...\n",
        "# currently not used ... \n",
        "def rankDict(DIN):\n",
        "    '''\n",
        "    reading a frequency dictionary from a file\n",
        "    '''\n",
        "    DTermRanks = {}\n",
        "    i = 0\n",
        "    IRank = 0\n",
        "    IPrevFrq = 0\n",
        "    SumRanks = 0\n",
        "    for SKey, Frq in DIN.items():\n",
        "        # if re.match('#', SKey): continue # skipping comments\n",
        "        i+=1\n",
        "        if IPrevFrq != Frq: IRank = i # rank is the number of the highest ranking element of the same frequency group\n",
        "        IPrevFrq = Frq\n",
        "        \n",
        "        DTermRanks[SKey] = IRank\n",
        "        SumRanks += IRank\n",
        "\n",
        "    AAveRank = SumRanks / i\n",
        "    print(f'MaxRank = {IRank}\\nAve Rank = {AAveRank}\\n')\n",
        "    return DTermRanks, AAveRank\n",
        "\n",
        "\n",
        "# Main evaluation function\n",
        "# One-directional comparision of dictionaries\n",
        "# one-directional comparison of two dictionaries; arguments: DGoldStandard (smaller) DTest (larger), file: GS items found in DTest; GS items missing from DText...\n",
        "# usually testing: smaller vs. bigger dictionaries\n",
        "def countIntersectDictionaries(DGS, DTest, FOutputPrecFOUND, FOutputPrecMISSING, SortBy = 0, Rev = False):\n",
        "    '''\n",
        "    general function: intersect dictionaries, return new intersection dictionaries, record \"in\" and \"out\" expressions\n",
        "    \n",
        "    3b: intersecting All possible MWEs in GS list with the \"Extracted\" list\n",
        "    DA (smaller and going over each element) with D1W / DMWE lists \n",
        "    '''\n",
        "\n",
        "    print('Total len of Gold Standard: ' + str(len(DGS.items())))\n",
        "    IFound = 0\n",
        "    IMissing = 0\n",
        "    SumFoundRanks = 0\n",
        "    DFound = {} # intersection dictionary\n",
        "\n",
        "    for Word, Frq in sorted(DGS.items(),  key=lambda x: x[SortBy], reverse=Rev):\n",
        "        if Word in DTest:\n",
        "            IFound += 1\n",
        "            try: # normally will not fire: if this word already exists with some rank, calculate the average of a new and old rank\n",
        "                r0 = DFound[Word]\n",
        "                r1 = DTest[Word]\n",
        "                r = (r0+r1)/2\n",
        "                DFound[Word] = r\n",
        "                print('r?')\n",
        "            except: # normal route: find the rank of the word in the dictionary\n",
        "                DFound[Word] = DTest[Word]\n",
        "\n",
        "            SumFoundRanks += DTest[Word] # add rank, to calculate average\n",
        "            try: FOutputPrecFOUND.write(Word + '\\t' + str(Frq) + '\\t' + str(DFound[Word]) + '\\n') # record/calculate average rank, etc.\n",
        "            except: \n",
        "                FOutputPrecFOUND.write(Word + '\\t' + str(Frq) + '\\t' + 'KEY ERROR' + '\\n')\n",
        "                print(Word + '\\t' + str(Frq) + '\\t' + 'KEY ERROR' + '\\n')\n",
        "        else:\n",
        "            IMissing += 1\n",
        "            FOutputPrecMISSING.write(Word + '\\t' + str(Frq) + '\\n') # record/calculate average rank, etc.\n",
        "\n",
        "    \n",
        "    # print(f'Found: {IFound}')\n",
        "    # print(f'Missing: {IMissing}')\n",
        "    try: ACoverage = IFound / len(DGS.items())\n",
        "    except: ACoverage = 0\n",
        "    # print(f'Found2LenGS: {ACoverage}')\n",
        "    try: AAverageFoundRanks = SumFoundRanks / IFound\n",
        "    except: AAverageFoundRanks = 0\n",
        "    # print(f'Ave Found Ranks: {AAverageFoundRanks} \\n')\n",
        "\n",
        "    print(f'Found: {IFound} ; Missing: {IMissing} ; AveRank: {AAverageFoundRanks} ; ACoverage: {ACoverage} ')\n",
        "    FOutputPrecFOUND.flush()\n",
        "    FOutputPrecMISSING.flush()\n",
        "\n",
        "    return ACoverage, AAverageFoundRanks, DFound\n",
        "\n",
        "\n",
        "\n",
        "# extracting annotated terms from the gold standard in xml format\n",
        "def vertCollectAnnotation(FInVert, SXmlTag):\n",
        "    L3AnnotatedSegs = []\n",
        "    L2Seg = [] # a list of the current segment -- eash string is added \n",
        "    BInTerm = False # boolean flag: inside / outside term\n",
        "    RTagOpen = re.compile('<' + SXmlTag + '>')\n",
        "    RTagClose = re.compile('</' + SXmlTag + '>')\n",
        "    for SLine in FInVert:\n",
        "        SLine = SLine.strip()\n",
        "        if re.match(RTagOpen, SLine):\n",
        "            BInTerm = True\n",
        "        elif re.match(RTagClose, SLine):\n",
        "            BInTerm = False\n",
        "            L3AnnotatedSegs.append(L2Seg)\n",
        "            L2Seg = []\n",
        "        else:\n",
        "            if BInTerm == True:\n",
        "                LFields = re.split('\\t', SLine)\n",
        "                L2Seg.append(LFields)\n",
        "\n",
        "    return L3AnnotatedSegs\n",
        "\n",
        "\n",
        "\n",
        "def convertBrecket2Xml(FInAnnot, FOutAnnot, RInOpen, RInClose, SOutOpen, SOutClose):\n",
        "    RCOpen = re.compile(RInOpen)\n",
        "    RCClose = re.compile(RInClose)\n",
        "    for SLine in FInAnnot:\n",
        "        SLine.strip()\n",
        "        SLine = re.sub(RCOpen, SOutOpen, SLine)\n",
        "        SLine = re.sub(RCClose, SOutClose, SLine)\n",
        "\n",
        "        FOutAnnot.write(SLine + '\\n')\n",
        "    FOutAnnot.flush()\n",
        "    return\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV3RKlelR6jx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObQNpab5JrOn"
      },
      "source": [
        "# read / generate all the necessary texts\n",
        "# first define functions, then download files and read them into dictionaries...\n",
        "## Annotated Gold Standard\n",
        "# Stage 1: Preparing Gold standard: Reading / extracting information from gold standard: creating a list of annotated terms\n",
        "# set 1 (same text annotated by two annotators)\n",
        "\n",
        "!wget https://heibox.uni-heidelberg.de/f/ae1110c4f9ad42b9a3d5/?dl=1\n",
        "!mv index.html?dl=1 BGH1_s00Astghik.txt\n",
        "!wget https://heibox.uni-heidelberg.de/f/398e7a10fa3241519f26/?dl=1\n",
        "!mv index.html?dl=1 BGH1_s00Maia.txt\n",
        "\n",
        "# set 2 (same text annotated by two annotators)\n",
        "!wget https://heibox.uni-heidelberg.de/f/0c787f26123f49178639/?dl=1\n",
        "!mv index.html?dl=1 BGH2_s00Hayk.txt\n",
        "!wget https://heibox.uni-heidelberg.de/f/356205b502fb4d759ad5/?dl=1\n",
        "!mv index.html?dl=1 BGH2_s00Nino.txt\n",
        "\n",
        "# set 3 (same text annotated by two annotators)\n",
        "!wget https://heibox.uni-heidelberg.de/f/ed0c7af9a9d04967b449/?dl=1\n",
        "!mv index.html?dl=1 BGH3_s00Tamar.txt\n",
        "# !wget \n",
        "# !mv index.html?dl=1\n",
        "\n",
        "# one more will be added: Frau Khachatryan\n",
        "!cat BGH1_s00Astghik.txt BGH1_s00Maia.txt BGH2_s00Hayk.txt BGH2_s00Nino.txt BGH3_s00Tamar.txt >BGH0_s00GoldStandard.txt\n",
        "\n",
        "FInBGH0_s00GoldStandard = open('BGH0_s00GoldStandard.txt', 'r')\n",
        "FOutBGH0_s00GoldStandard = open('BGH0_s00GoldStandard_xml.txt', 'w')\n",
        "\n",
        "convertBrecket2Xml(FInBGH0_s00GoldStandard, FOutBGH0_s00GoldStandard, '<<+', '>>+', '<TERM>', '</TERM>')\n",
        "# this result is pos-tagged and uploaded in the next step\n",
        "# command:\n",
        "# tree-tagger-de.sh /Users/bogdan/Seafile/research/corpus/DAAD-corpus/daad-experiments/BGH0_s00GoldStandard_xml.txt >/Users/bogdan/Seafile/research/corpus/DAAD-corpus/daad-experiments/BGH0_s00GoldStandard_LEM.txt\n",
        "\n",
        "# further versions of the Gold Standard: \n",
        "# Annotated and PoS-tagged Gold Standard -- for extraction of the correct evaluation set\n",
        "\n",
        "# printing words of different length\n",
        "FOutput = open('BGH0_s01GoldS_Terms.txt', 'w')\n",
        "FOutputDict1w = open('BGH0_s01GoldS_D1w.txt', 'w') # 1-word terms\n",
        "FOutputDict2w = open('BGH0_s01GoldS_D2w.txt', 'w') # 2-word terminological expressions\n",
        "FOutputDict3w = open('BGH0_s01GoldS_D3w.txt', 'w') # 3-word terminological expressions\n",
        "FOutputDict4w = open('BGH0_s01GoldS_DMWE.txt', 'w') # more than 3 words\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHL3gREljDnQ"
      },
      "source": [
        "# !wget https://heibox.uni-heidelberg.de/f/4e719e0466a143c0b1b5/?dl=1\n",
        "!wget https://heibox.uni-heidelberg.de/f/d8f1bb53632d40538e0d/?dl=1\n",
        "!mv index.html?dl=1 BGH0_s00GS_LEM.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA9UNO0NZbt0"
      },
      "source": [
        "# reading datasets\n",
        "# list of gold-standard annotated terms, with lemmatization and pos fileds\n",
        "FInBGH0_s00GS_LEM = open('BGH0_s00GS_LEM.txt', 'r')\n",
        "# FOutBGH0_s00GS_Terms = open('BGH0_s00GS_Terms.txt', 'w')\n",
        "L3AnnotatedSegs = vertCollectAnnotation(FInBGH0_s00GS_LEM, 'TERM')\n",
        "\n",
        "# testing the file read\n",
        "# for LSegment in L3AnnotatedSegs: FOutBGH0_s00GS_Terms.write(str(LSegment) + '\\n')\n",
        "# FOutBGH0_s00GS_Terms.flush()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPE39kkEAOwZ",
        "outputId": "2d533a93-cb22-4a18-c74d-b02fa64ca905"
      },
      "source": [
        "L3AnnotatedSegs[10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Oberstaatsanwalt', 'NN', 'Oberstaatsanwalt'],\n",
              " ['beim', 'APPRART', 'bei'],\n",
              " ['Bundesgerichtshof', 'NN', 'Bundesgerichtshof']]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3_PKbspAYMD"
      },
      "source": [
        "def createDictOfPatterns(L3AnnotatedSegs, IFieldN, Normalize = False):\n",
        "    '''\n",
        "    take the list of annotated terms and return a dictionary of MWEs\n",
        "    '''\n",
        "    DPatternsFrq = {} # returned dictionary of PoS patterns, etc.\n",
        "    for L2TermFlds in L3AnnotatedSegs:\n",
        "        LFlds = [] # here we will collect the values of the selected field\n",
        "        for LWordFlds in L2TermFlds:\n",
        "            if Normalize:\n",
        "                try: PoS = LWordFlds[IFieldN]\n",
        "                except: \n",
        "                    print('PoS not found')\n",
        "                    PoS = ''\n",
        "                if re.match('N', PoS): LWordFlds[IFieldN] = 'N'\n",
        "                if re.match('ADJ', PoS): LWordFlds[IFieldN] = 'ADJ'\n",
        "                if re.match('V', PoS): LWordFlds[IFieldN] = 'V'\n",
        "            try: LFlds.append(LWordFlds[IFieldN])\n",
        "            except: print('index Error')\n",
        "        if len(LFlds) > 0: SFlds = ' '.join(LFlds)\n",
        "        try: DPatternsFrq[SFlds] += 1\n",
        "        except: DPatternsFrq[SFlds] = 1\n",
        "\n",
        "    return DPatternsFrq\n",
        "\n",
        "DPatternsFrq = createDictOfPatterns(L3AnnotatedSegs, 1, Normalize = True)\n",
        "FOutTermPOS = open('BGH0_s00GoldStandard_pos.txt', 'w')\n",
        "\n",
        "printDictionary(DPatternsFrq, FOutTermPOS)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "4x_kJbRh3TDa",
        "outputId": "0c2cdc7f-e660-48e5-c6e7-580f4e792128"
      },
      "source": [
        "# L3AnnotatedSegs[10]\n",
        "# FInput = open('BGH0_s00GoldStandard.txt', 'r')\n",
        "# for statistical purposes - separately single and multiword terms\n",
        "\n",
        "def comparePattern(L2TermFlds, LPattern, IFldN):\n",
        "    '''\n",
        "    compares if a pattern is found in the term field\n",
        "    '''\n",
        "    for k in range(len(LPattern)):\n",
        "        if re.match(LPattern[k], L2TermFlds[k][IFldN]): continue\n",
        "        else: return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def selectTerms(L3AnnotatedSegs, L2Patterns = None, LNoEdge = None, LNoStart = None, L2NoEnd = None,  SplitLen = False, IFldNumber = 0):\n",
        "    '''\n",
        "    function: 1. selects terms which match specified POS pattern; 2. divides them into dictionaries according to length\n",
        "    the function can also visualise terms with a specific pos pattern, specified in L2Patterns, e.g., L2Patterns = [['N', '\\$']]\n",
        "\n",
        "    '''\n",
        "    DGS = {}\n",
        "    DGS1w = {} # dictionary of single words\n",
        "    DGS2w = {} # dictionary of 2-word expressions\n",
        "    DGS3w = {} # dictionary of 3-word expressions\n",
        "    DGS4w = {} # dictionary of other mwes\n",
        "    IGS = 0\n",
        "    IGS1w = 0 # number of annotated tokens of single words\n",
        "    IGS2w = 0\n",
        "    IGS3w = 0\n",
        "    IGS4w = 0 # number of annotated tokens of multiwords\n",
        "\n",
        "    if L2Patterns: # positive filter\n",
        "        for L2AnnotatedSeg in L3AnnotatedSegs: # for each multiword term, where words are represented as fields\n",
        "            ILenTerm = len(L2AnnotatedSeg)\n",
        "            for LPattern in L2Patterns:\n",
        "                if len(LPattern) == ILenTerm and comparePattern(L2AnnotatedSeg, LPattern, 1):\n",
        "                    LTerm = []\n",
        "                    for LTerm2Fields in L2AnnotatedSeg:\n",
        "                        LTerm.append(LTerm2Fields[IFldNumber])\n",
        "                    STerm = ' '.join(LTerm)\n",
        "                    try: DGS[STerm] += 1\n",
        "                    except: DGS[STerm] = 1\n",
        "\n",
        "    else: # negative filter checking\n",
        "        for L2AnnotatedSeg in L3AnnotatedSegs:\n",
        "            if LNoEdge: # PoS which cannot apper at the edge\n",
        "                for SPoS in LNoEdge:\n",
        "                    if re.match(SPoS, L2AnnotatedSeg[-1][1]) or re.match(SPoS, L2AnnotatedSeg[0][1]): \n",
        "                        continue\n",
        "            if LNoStart:\n",
        "                for SPoS in LNoStart:\n",
        "                    if re.match(re.match(SPoS, L2AnnotatedSeg[0][1])): \n",
        "                        continue\n",
        "            if L2NoEnd:\n",
        "                for SPoS in L2NoEnd:\n",
        "                    if re.match(re.match(SPoS, L2AnnotatedSeg[-1][1])): \n",
        "                        continue\n",
        "            LTerm = []\n",
        "            for LTerm2Fields in L2AnnotatedSeg:\n",
        "                LTerm.append(LTerm2Fields[IFldNumber])\n",
        "            STerm = ' '.join(LTerm)\n",
        "            try: DGS[STerm] += 1\n",
        "            except: DGS[STerm] = 1\n",
        "                         \n",
        "\n",
        "    return DGS\n",
        "\n",
        "# DTermConfFrq = selectTerms(L3AnnotatedSegs, L2Patterns = [['N', '\\$']], SplitLen = False, IFldNumber = 0)\n",
        "# FOutExamples = open('BGH0_s00GoldStandard_examples_ADJ_N.txt', 'w')\n",
        "\n",
        "DTermConfFrq = selectTerms(L3AnnotatedSegs, L2Patterns = None, LNoEdge = None, LNoStart = None, L2NoEnd = ['ADJ'], SplitLen = False, IFldNumber = 0)\n",
        "FOutExamples = open('BGH0_s00GoldStandard_examples.txt', 'w')\n",
        "\n",
        "printDictionary(DTermConfFrq, FOutExamples)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-c20211647d59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# FOutExamples = open('BGH0_s00GoldStandard_examples_ADJ_N.txt', 'w')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mDTermConfFrq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselectTerms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL3AnnotatedSegs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL2Patterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLNoEdge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLNoStart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL2NoEnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ADJ'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSplitLen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIFldNumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0mFOutExamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BGH0_s00GoldStandard_examples.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-c20211647d59>\u001b[0m in \u001b[0;36mselectTerms\u001b[0;34m(L3AnnotatedSegs, L2Patterns, LNoEdge, LNoStart, L2NoEnd, SplitLen, IFldNumber)\u001b[0m\n\u001b[1;32m     52\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mL2NoEnd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSPoS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL2AnnotatedSeg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mLTerm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'SPoS' referenced before assignment"
          ]
        }
      ]
    }
  ]
}