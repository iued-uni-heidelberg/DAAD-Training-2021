{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Terminologieextraktion9EvaluationKeyWordsV02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPiMYTpY8HdYEbOTVodWhpi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/DAAD-Training-2021/blob/main/Terminologieextraktion9EvaluationKeyWordsV02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x08Plvp9F_mA"
      },
      "source": [
        "# Stage 0: Some useful read/write and convert functions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsmKBqMgGWLf"
      },
      "source": [
        "# import useful libraries, files\n",
        "\n",
        "import re, os, sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ9Hkx0OGfCt"
      },
      "source": [
        "# file for recording results of different configurations\n",
        "# run this only once\n",
        "!rm AllTermExtractionResultsV01.txt\n",
        "!rm AllTermExtractionResultsV02.txt\n",
        "\n",
        "FOutResults1 = open('AllTermExtractionResultsV01.txt', 'a')\n",
        "FOutResults2 = open('AllTermExtractionResultsV02.txt', 'a')\n",
        "FOutResults1.write('Run\\tW1A\\tW1B\\tW1C\\tW1D\\tW1P\\tW1R\\tW2A\\tW2B\\tW2C\\tW2D\\tW2P\\tW2R\\tW3A\\tW3B\\tW3C\\tW3D\\tW3P\\tW3R\\tW4A\\tW4B\\tW4C\\tW4D\\tW4P\\tW4R\\n')\n",
        "FOutResults2.write('Run\\tW1P\\tW1R\\tW2P\\tW2R\\tW3P\\tW3R\\tW4P\\tW4R\\n') # only precision and recall figures\n",
        "FOutResults1.flush()\n",
        "FOutResults2.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqvEq6IGGfv1"
      },
      "source": [
        "## to modify if necessary; however, we try to keep the code standard and parametrize as much as possible\n",
        "\n",
        "# useful functions\n",
        "# a useful function for recording / visualising current stage of dictionaries\n",
        "def printDictionary(DictionaryFrq, FOut, K = 1, Rev = True): # printing a dictionary: by values or alphabetically\n",
        "    for Word, Frq in sorted( DictionaryFrq.items() , key=lambda x: x[K], reverse=Rev):\n",
        "        FOut.write(Word + '\\t' + str(Frq) + '\\n')\n",
        "    FOut.flush()\n",
        "    return\n",
        "\n",
        "# another useful function to just read and return a 2-field dictionary, eg., frequency or keyness\n",
        "def readDictionary(FIN, SkipComments = True, Caps=False):\n",
        "    DScoresLarge = {} # keywords - scores\n",
        "    for Line in FIN:\n",
        "        if SkipComments and re.match('#', Line): \n",
        "            continue\n",
        "        Line = Line.strip()\n",
        "        if Caps: \n",
        "            Line = Line.upper() # convert to upper case\n",
        "        LFieldsKW = re.split('\\t', Line)\n",
        "        SWord = LFieldsKW[0]\n",
        "        AKScore = float(LFieldsKW[1])\n",
        "        DScoresLarge[SWord] = AKScore   \n",
        "    return DScoresLarge\n",
        "\n",
        "# another possibly useful function: convert dictionary values to ranks (frequency, keyness weights, etc.)\n",
        "# for understanding how far down the list the item has been found...\n",
        "# currently not used ... \n",
        "def rankDict(DIN):\n",
        "    '''\n",
        "    reading a frequency dictionary from a file\n",
        "    '''\n",
        "    DTermRanks = {}\n",
        "    i = 0\n",
        "    IRank = 0\n",
        "    IPrevFrq = 0\n",
        "    SumRanks = 0\n",
        "    for SKey, Frq in DIN.items():\n",
        "        # if re.match('#', SKey): continue # skipping comments\n",
        "        i+=1\n",
        "        if IPrevFrq != Frq: IRank = i # rank is the number of the highest ranking element of the same frequency group\n",
        "        IPrevFrq = Frq\n",
        "        \n",
        "        DTermRanks[SKey] = IRank\n",
        "        SumRanks += IRank\n",
        "\n",
        "    AAveRank = SumRanks / i\n",
        "    print(f'MaxRank = {IRank}\\nAve Rank = {AAveRank}\\n')\n",
        "    return DTermRanks, AAveRank\n",
        "\n",
        "\n",
        "# Main evaluation function\n",
        "# One-directional comparision of dictionaries\n",
        "# one-directional comparison of two dictionaries; arguments: DGoldStandard (smaller) DTest (larger), file: GS items found in DTest; GS items missing from DText...\n",
        "# usually testing: smaller vs. bigger dictionaries\n",
        "def countIntersectDictionaries(DGS, DTest, FOutputPrecFOUND, FOutputPrecMISSING, SortBy = 0, Rev = False):\n",
        "    '''\n",
        "    general function: intersect dictionaries, return new intersection dictionaries, record \"in\" and \"out\" expressions\n",
        "    \n",
        "    3b: intersecting All possible MWEs in GS list with the \"Extracted\" list\n",
        "    DA (smaller and going over each element) with D1W / DMWE lists \n",
        "    '''\n",
        "\n",
        "    print('Total len of Gold Standard: ' + str(len(DGS.items())))\n",
        "    IFound = 0\n",
        "    IMissing = 0\n",
        "    SumFoundRanks = 0\n",
        "    DFound = {} # intersection dictionary\n",
        "\n",
        "    for Word, Frq in sorted(DGS.items(),  key=lambda x: x[SortBy], reverse=Rev):\n",
        "        if Word in DTest:\n",
        "            IFound += 1\n",
        "            try: # normally will not fire: if this word already exists with some rank, calculate the average of a new and old rank\n",
        "                r0 = DFound[Word]\n",
        "                r1 = DTest[Word]\n",
        "                r = (r0+r1)/2\n",
        "                DFound[Word] = r\n",
        "                print('r?')\n",
        "            except: # normal route: find the rank of the word in the dictionary\n",
        "                DFound[Word] = DTest[Word]\n",
        "\n",
        "            SumFoundRanks += DTest[Word] # add rank, to calculate average\n",
        "            try: FOutputPrecFOUND.write(Word + '\\t' + str(Frq) + '\\t' + str(DFound[Word]) + '\\n') # record/calculate average rank, etc.\n",
        "            except: \n",
        "                FOutputPrecFOUND.write(Word + '\\t' + str(Frq) + '\\t' + 'KEY ERROR' + '\\n')\n",
        "                print(Word + '\\t' + str(Frq) + '\\t' + 'KEY ERROR' + '\\n')\n",
        "        else:\n",
        "            IMissing += 1\n",
        "            FOutputPrecMISSING.write(Word + '\\t' + str(Frq) + '\\n') # record/calculate average rank, etc.\n",
        "\n",
        "    \n",
        "    # print(f'Found: {IFound}')\n",
        "    # print(f'Missing: {IMissing}')\n",
        "    try: ACoverage = IFound / len(DGS.items())\n",
        "    except: ACoverage = 0\n",
        "    # print(f'Found2LenGS: {ACoverage}')\n",
        "    try: AAverageFoundRanks = SumFoundRanks / IFound\n",
        "    except: AAverageFoundRanks = 0\n",
        "    # print(f'Ave Found Ranks: {AAverageFoundRanks} \\n')\n",
        "\n",
        "    print(f'Found: {IFound} ; Missing: {IMissing} ; AveRank: {AAverageFoundRanks} ; ACoverage: {ACoverage} ')\n",
        "    FOutputPrecFOUND.flush()\n",
        "    FOutputPrecMISSING.flush()\n",
        "\n",
        "    return ACoverage, AAverageFoundRanks, DFound\n",
        "\n",
        "\n",
        "\n",
        "# extracting annotated terms from the gold standard in xml format\n",
        "def vertCollectAnnotation(FInVert, SXmlTag):\n",
        "    L3AnnotatedSegs = []\n",
        "    L2Seg = [] # a list of the current segment -- eash string is added \n",
        "    BInTerm = False # boolean flag: inside / outside term\n",
        "    RTagOpen = re.compile('<' + SXmlTag + '>')\n",
        "    RTagClose = re.compile('</' + SXmlTag + '>')\n",
        "    for SLine in FInVert:\n",
        "        SLine = SLine.strip()\n",
        "        if re.match(RTagOpen, SLine):\n",
        "            BInTerm = True\n",
        "        elif re.match(RTagClose, SLine):\n",
        "            BInTerm = False\n",
        "            L3AnnotatedSegs.append(L2Seg)\n",
        "            L2Seg = []\n",
        "        else:\n",
        "            if BInTerm == True:\n",
        "                LFields = re.split('\\t', SLine)\n",
        "                L2Seg.append(LFields)\n",
        "\n",
        "    return L3AnnotatedSegs\n",
        "\n",
        "\n",
        "\n",
        "def convertBrecket2Xml(FInAnnot, FOutAnnot, RInOpen, RInClose, SOutOpen, SOutClose):\n",
        "    RCOpen = re.compile(RInOpen)\n",
        "    RCClose = re.compile(RInClose)\n",
        "    for SLine in FInAnnot:\n",
        "        SLine.strip()\n",
        "        SLine = re.sub(RCOpen, SOutOpen, SLine)\n",
        "        SLine = re.sub(RCClose, SOutClose, SLine)\n",
        "\n",
        "        FOutAnnot.write(SLine + '\\n')\n",
        "    FOutAnnot.flush()\n",
        "    return\n",
        "  "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV3RKlelR6jx"
      },
      "source": [
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObQNpab5JrOn"
      },
      "source": [
        "# read / generate all the necessary texts\n",
        "# first define functions, then download files and read them into dictionaries...\n",
        "## Annotated Gold Standard\n",
        "# Stage 1: Preparing Gold standard: Reading / extracting information from gold standard: creating a list of annotated terms\n",
        "# set 1 (same text annotated by two annotators)\n",
        "\n",
        "!wget https://heibox.uni-heidelberg.de/f/ae1110c4f9ad42b9a3d5/?dl=1\n",
        "!mv index.html?dl=1 BGH1_s00Astghik.txt\n",
        "!wget https://heibox.uni-heidelberg.de/f/398e7a10fa3241519f26/?dl=1\n",
        "!mv index.html?dl=1 BGH1_s00Maia.txt\n",
        "\n",
        "# set 2 (same text annotated by two annotators)\n",
        "!wget https://heibox.uni-heidelberg.de/f/0c787f26123f49178639/?dl=1\n",
        "!mv index.html?dl=1 BGH2_s00Hayk.txt\n",
        "!wget https://heibox.uni-heidelberg.de/f/356205b502fb4d759ad5/?dl=1\n",
        "!mv index.html?dl=1 BGH2_s00Nino.txt\n",
        "\n",
        "# set 3 (same text annotated by two annotators)\n",
        "!wget https://heibox.uni-heidelberg.de/f/ed0c7af9a9d04967b449/?dl=1\n",
        "!mv index.html?dl=1 BGH3_s00Tamar.txt\n",
        "# !wget \n",
        "# !mv index.html?dl=1\n",
        "\n",
        "# one more will be added: Frau Khachatryan\n",
        "!cat BGH1_s00Astghik.txt BGH1_s00Maia.txt BGH2_s00Hayk.txt BGH2_s00Nino.txt BGH3_s00Tamar.txt >BGH0_s00GoldStandard.txt\n",
        "\n",
        "FInBGH0_s00GoldStandard = open('BGH0_s00GoldStandard.txt', 'r')\n",
        "FOutBGH0_s00GoldStandard = open('BGH0_s00GoldStandard_xml.txt', 'w')\n",
        "\n",
        "convertBrecket2Xml(FInBGH0_s00GoldStandard, FOutBGH0_s00GoldStandard, '<<+', '>>+', '<TERM>', '</TERM>')\n",
        "# this result is pos-tagged and uploaded in the next step\n",
        "# command:\n",
        "# tree-tagger-de.sh /Users/bogdan/Seafile/research/corpus/DAAD-corpus/daad-experiments/BGH0_s00GoldStandard_xml.txt >/Users/bogdan/Seafile/research/corpus/DAAD-corpus/daad-experiments/BGH0_s00GoldStandard_LEM.txt\n",
        "\n",
        "# further versions of the Gold Standard: \n",
        "# Annotated and PoS-tagged Gold Standard -- for extraction of the correct evaluation set\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHL3gREljDnQ",
        "outputId": "c6a387f2-e131-4da3-c404-be9fe5690fd1"
      },
      "source": [
        "# !wget https://heibox.uni-heidelberg.de/f/4e719e0466a143c0b1b5/?dl=1\n",
        "!wget https://heibox.uni-heidelberg.de/f/d8f1bb53632d40538e0d/?dl=1\n",
        "!mv index.html?dl=1 BGH0_s00GS_LEM.txt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-29 14:55:20--  https://heibox.uni-heidelberg.de/f/d8f1bb53632d40538e0d/?dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/7b0d7a29-7899-4283-b074-77e458e56f24/BGH0_s00GoldStandard_LEM.txt [following]\n",
            "--2021-10-29 14:55:21--  https://heibox.uni-heidelberg.de/seafhttp/files/7b0d7a29-7899-4283-b074-77e458e56f24/BGH0_s00GoldStandard_LEM.txt\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 0 [text/plain]\n",
            "Saving to: ‘index.html?dl=1’\n",
            "\n",
            "index.html?dl=1         [ <=>                ]       0  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-29 14:55:21 (0.00 B/s) - ‘index.html?dl=1’ saved [0/0]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA9UNO0NZbt0"
      },
      "source": [
        "FInBGH0_s00GS_LEM = open('BGH0_s00GS_LEM.txt', 'r')\n",
        "FOutBGH0_s00GS_Terms = open('BGH0_s00GS_Terms.txt', 'w')\n",
        "LLAnnotatedSegs = vertCollectAnnotation(FInBGH0_s00GS_LEM, 'TERM')\n",
        "\n",
        "for LSegment in LLAnnotatedSegs:\n",
        "    FOutBGH0_s00GS_Terms.write(str(LSegment) + '\\n')\n",
        "\n",
        "FOutBGH0_s00GS_Terms.flush()"
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}