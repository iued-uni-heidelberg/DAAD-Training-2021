{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "compLingProject101MorphologicalAnalysisV01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNwLsKFvnPHhhY4F3usVlfr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/DAAD-Training-2021/blob/main/compLingProject101MorphologicalAnalysisV01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1dRDzwnNTst"
      },
      "source": [
        "# Morphological analysis for English and Armenian\n",
        "\n",
        "We will create a workflow for analysing English and Armenian texts\n",
        "\n",
        "For English we will use the TreeTagger \n",
        "\n",
        "For Armenian we will use the git repository with Armenian morphological analyser: \n",
        "https://github.com/timarkh/uniparser-grammar-eastern-armenian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nX7LqgRytTb"
      },
      "source": [
        "# importing python libraries\n",
        "import os, re, sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HjwCMIqsztj"
      },
      "source": [
        "## English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp8FKqOANJ6A"
      },
      "source": [
        "# installing TreeTagger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUlWsn6UmgZb"
      },
      "source": [
        "%%bash\n",
        "mkdir treetagger\n",
        "cd treetagger\n",
        "# Download the tagger package for your system (PC-Linux, Mac OS-X, ARM64, ARMHF, ARM-Android, PPC64le-Linux).\n",
        "wget https://cis.lmu.de/~schmid/tools/TreeTagger/data/tree-tagger-linux-3.2.4.tar.gz\n",
        "tar -xzvf tree-tagger-linux-3.2.4.tar.gz\n",
        "# Download the tagging scripts into the same directory.\n",
        "wget https://cis.lmu.de/~schmid/tools/TreeTagger/data/tagger-scripts.tar.gz\n",
        "gunzip tagger-scripts.tar.gz\n",
        "# Download the installation script install-tagger.sh.\n",
        "wget https://cis.lmu.de/~schmid/tools/TreeTagger/data/install-tagger.sh\n",
        "# Download the parameter files for the languages you want to process.\n",
        "# list of all files (parameter files) https://cis.lmu.de/~schmid/tools/TreeTagger/#parfiles\n",
        "wget https://cis.lmu.de/~schmid/tools/TreeTagger/data/english.par.gz\n",
        "sh install-tagger.sh\n",
        "cd ..\n",
        "sudo pip install treetaggerwrapper\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VR2d5n_mo8R"
      },
      "source": [
        "%%bash\n",
        "wget https://heibox.uni-heidelberg.de/f/c888756380ba4f42b210/?dl=1\n",
        "mv index.html?dl=1 humanrights_hy.txt\n",
        "\n",
        "wget https://heibox.uni-heidelberg.de/f/95a3875771c040db959a/?dl=1\n",
        "mv index.html?dl=1 humanrights02.txt\n",
        "\n",
        "wget https://heibox.uni-heidelberg.de/f/cdf240db84ca4718b718/?dl=1\n",
        "mv index.html?dl=1 en1984.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NYDVbfzzpdK"
      },
      "source": [
        "!head --lines=20 humanrights_hy.txt\n",
        "!wc humanrights_hy.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMxbGb2-m58C"
      },
      "source": [
        "!head --lines=20 humanrights02.txt\n",
        "!wc humanrights02.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HYUJAY5rAte"
      },
      "source": [
        "!./treetagger/cmd/tree-tagger-english en1984.txt >en1984_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PNvmwwVrwyn"
      },
      "source": [
        "!head --lines=20 en1984_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7stVR-G1rFat"
      },
      "source": [
        "!./treetagger/cmd/tree-tagger-english humanrights02.txt >humanrights02_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf0ZClfLrZd3"
      },
      "source": [
        "!head --lines=20 humanrights02_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC5cBgvas4vQ"
      },
      "source": [
        "## Armenian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW7HUG3TQzjU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd21cc68-fd86-45ee-a24b-1ce465fbc197"
      },
      "source": [
        "# installing Armenian morphological analyser\n",
        "!git clone https://github.com/timarkh/uniparser-grammar-eastern-armenian"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'uniparser-grammar-eastern-armenian'...\n",
            "remote: Enumerating objects: 170, done.\u001b[K\n",
            "remote: Counting objects: 100% (170/170), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 170 (delta 77), reused 165 (delta 72), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (170/170), 33.36 MiB | 16.08 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgrVLqTTStuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb9e10c-e069-429c-f7ff-d33dca5b1c2a"
      },
      "source": [
        "# Python classes\n",
        "!pip3 install uniparser-eastern-armenian"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uniparser-eastern-armenian\n",
            "  Downloading uniparser_eastern_armenian-2.1.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from uniparser-eastern-armenian) (5.4.0)\n",
            "Collecting uniparser-morph>=2.2.0\n",
            "  Downloading uniparser_morph-2.4.2-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->uniparser-eastern-armenian) (3.6.0)\n",
            "Installing collected packages: uniparser-morph, uniparser-eastern-armenian\n",
            "Successfully installed uniparser-eastern-armenian-2.1.1 uniparser-morph-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bALlnO8gY4cF"
      },
      "source": [
        "# disambiguation\n",
        "!sudo apt-get install cg3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5-Y0JQES0oT"
      },
      "source": [
        "from uniparser_eastern_armenian import EasternArmenianAnalyzer\n",
        "a = EasternArmenianAnalyzer()\n",
        "analyses = a.analyze_words('Ձևաբանություն')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1gZH7s3XfMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d02da1f9-c397-47a3-87c4-8020cd83371d"
      },
      "source": [
        "for ana in analyses:\n",
        "    print(ana.wf, ana.lemma, ana.gramm, ana.gloss, ana.stem, ana.subwords, ana.wfGlossed, ana.otherData)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ձևաբանություն ձեւաբանություն N,inanim,sg,nom,nonposs morphology ձևաբանություն. [] ձևաբանություն [('trans_en', 'morphology')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqmYRwfBlbNo"
      },
      "source": [
        "dir(ana)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ddvunxGTXQf"
      },
      "source": [
        "analyses = a.analyze_words([['և'], ['Ես', 'սիրում', 'եմ', 'քեզ', ':']],\n",
        "                           format='xml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuOyUBXmTbep"
      },
      "source": [
        "for ana in analyses:\n",
        "    print(str(ana))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWxToCMSTyL6"
      },
      "source": [
        "analyses = a.analyze_words(['Ձևաբանություն', [['և'], ['Ես', 'սիրում', 'եմ', 'քեզ', ':']]],\n",
        "                           format='json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxEQfFZvT1KM"
      },
      "source": [
        "for ana in analyses:\n",
        "    print(str(ana))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWNEo_RwUcSB"
      },
      "source": [
        "# analysis with disambiguation\n",
        "analyses = a.analyze_words(['Ես', 'սիրում', 'եմ', 'քեզ'], disambiguate=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRb9dCQoUdJc",
        "outputId": "1bacdf6a-ae49-4b90-f6d8-d1bc16699002"
      },
      "source": [
        "for ana in analyses:\n",
        "    for wfo in ana:\n",
        "        print(wfo.wf, wfo.lemma, wfo.gramm, wfo.gloss)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ես ես PRON,S,hum,sg,nom me\n",
            "Ես է V,intr,prs,sg,2 be-PRS.2SG\n",
            "սիրում սիրել V,tr,cvb,ipfv love-CVB.IPFV\n",
            "եմ է V,intr,prs,sg,1 be-PRS.1SG\n",
            "քեզ դու PRON,S,hum,sg,dat thou\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vzlcQSQlw55"
      },
      "source": [
        "print(type(wfo))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0P_zV02ZxQ8"
      },
      "source": [
        "dir(wfo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzINXeL7s9EL"
      },
      "source": [
        "# downloading and analysing texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJzA4Fg9tCaH"
      },
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/e0bfae444a5a4c76957b/?dl=1\n",
        "!mv index.html?dl=1 hy1984.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOXdvc_9uv0J"
      },
      "source": [
        "FInText = open('hy1984.txt','r')\n",
        "FOutText = open('hy1984_vert.txt','w')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWiOuQ7hz0xp"
      },
      "source": [
        "FInText = open('humanrights_hy.txt','r')\n",
        "FOutText = open('humanrights_hy_vert.txt','w')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdxZiI7ZyLGW"
      },
      "source": [
        "for SLine in FInText:\n",
        "    SLine = SLine.strip()\n",
        "    ListOfWords = re.split('[ ,\\.:;\\!\\(\\)\\\"\\[\\]՞՝«»\\-\\—՝։\\։]+', SLine) # tokenize: split on white spaces and punctuation\n",
        "    # if len(ListOfWords) > 0: FOutText.write(str(ListOfWords) + '\\n')\n",
        "    analyses = a.analyze_words(ListOfWords, disambiguate=False)\n",
        "    FOutText.write('<p>\\n')\n",
        "    for ana in analyses:\n",
        "        # for wfo in ana:\n",
        "        # how to type all variants + disambiguate ?\n",
        "        wfo = ana[0]\n",
        "        FOutText.write(wfo.wf + '\\t' + wfo.gramm + '\\t' + wfo.lemma + '\\t' + wfo.gloss + '\\n')\n",
        "        #    FOutText.write(wfo.wf + '\\t' + wfo.gramm + '\\t' + wfo.lemma + '\\t' + wfo.gloss + '\\n')\n",
        "    FOutText.write('</p>\\n')\n",
        "FOutText.flush()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}