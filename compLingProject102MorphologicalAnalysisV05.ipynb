{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "compLingProject102MorphologicalAnalysisV05.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNI18CacJVvvinvJ7HhlQg9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/DAAD-Training-2021/blob/main/compLingProject102MorphologicalAnalysisV05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1dRDzwnNTst"
      },
      "source": [
        "# Morphological analysis for English, German, Georgian and Armenian\n",
        "\n",
        "We will create a workflow for analysing English and Armenian texts\n",
        "\n",
        "For English, German and Georgian we will use the TreeTagger \n",
        "\n",
        "For Armenian we will use the git repository with Armenian morphological analyser: \n",
        "https://github.com/timarkh/uniparser-grammar-eastern-armenian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nX7LqgRytTb"
      },
      "source": [
        "# importing python libraries\n",
        "import os, re, sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HjwCMIqsztj"
      },
      "source": [
        "## English\n",
        "- installing TreeTagger\n",
        "- here we tag English Wikipedia\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUlWsn6UmgZb"
      },
      "source": [
        "%%bash\n",
        "mkdir treetagger\n",
        "cd treetagger\n",
        "# Download the tagger package for your system (PC-Linux, Mac OS-X, ARM64, ARMHF, ARM-Android, PPC64le-Linux).\n",
        "wget https://cis.lmu.de/~schmid/tools/TreeTagger/data/tree-tagger-linux-3.2.4.tar.gz\n",
        "tar -xzvf tree-tagger-linux-3.2.4.tar.gz\n",
        "# Download the tagging scripts into the same directory.\n",
        "wget https://cis.lmu.de/~schmid/tools/TreeTagger/data/tagger-scripts.tar.gz\n",
        "gunzip tagger-scripts.tar.gz\n",
        "# Download the installation script install-tagger.sh.\n",
        "wget https://cis.lmu.de/~schmid/tools/TreeTagger/data/install-tagger.sh\n",
        "# Download the parameter files for the languages you want to process.\n",
        "# list of all files (parameter files) https://cis.lmu.de/~schmid/tools/TreeTagger/#parfiles\n",
        "wget https://cis.lmu.de/~schmid/tools/TreeTagger/data/english.par.gz\n",
        "sh install-tagger.sh\n",
        "cd ..\n",
        "sudo pip install treetaggerwrapper\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# correcting cmd file: adding 'no-unknown' option:\n",
        "!mv /content/treetagger/cmd/tree-tagger-english /content/tree-tagger-english0\n",
        "!awk '{ if (NR == 9) print \"OPTIONS=\\\"-token -lemma -sgml -no-unknown\\\"\"; else print $0}' /content/tree-tagger-english0 > /content/treetagger/cmd/tree-tagger-english"
      ],
      "metadata": {
        "id": "V-UiRyFy2odm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "chmod a+x ./treetagger/cmd/tree-tagger-english"
      ],
      "metadata": {
        "id": "2f3djMC0E22g"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VR2d5n_mo8R"
      },
      "source": [
        "%%bash\n",
        "#first 100MB from English wikipedia:\n",
        "wget https://heibox.uni-heidelberg.de/f/6da08e0c242f4dc4a28f/?dl=1\n",
        "mv index.html?dl=1 wikien_17MW.txt.gz\n",
        "gunzip wikien_17MW.txt.gz\n",
        "\n",
        "\n",
        "# wget https://heibox.uni-heidelberg.de/f/95a3875771c040db959a/?dl=1\n",
        "# mv index.html?dl=1 humanrights02.txt\n",
        "\n",
        "# wget https://heibox.uni-heidelberg.de/f/cdf240db84ca4718b718/?dl=1\n",
        "# mv index.html?dl=1 en1984.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head --lines=25 wikien_17MW.txt\n",
        "!wc wikien_17MW.txt"
      ],
      "metadata": {
        "id": "qM5Ys6il_mH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./treetagger/cmd/tree-tagger-english wikien_17MW.txt >wikien_17MW_vert.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50OKN2AM_tCm",
        "outputId": "dfb64fe5-3127-4aa5-a3e1-382f376bbf92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\treading parameters ...\n",
            "\ttagging ...\n",
            "772000"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# all English wikipedia\n",
        "wget https://heibox.uni-heidelberg.de/f/0be6af6c18fe461285a4/?dl=1\n",
        "mv index.html?dl=1 en.txt.gz\n",
        "gunzip en.txt.gz"
      ],
      "metadata": {
        "id": "wv-z_4Ue_ir2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMxbGb2-m58C"
      },
      "source": [
        "!head --lines=25 en.txt\n",
        "!wc en.txt\n",
        "\n",
        "# !head --lines=20 humanrights02.txt\n",
        "# !wc humanrights02.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HYUJAY5rAte"
      },
      "source": [
        "!./treetagger/cmd/tree-tagger-english en.txt >en_vert.txt\n",
        "# !./treetagger/cmd/tree-tagger-english en1984.txt >en1984_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PNvmwwVrwyn"
      },
      "source": [
        "!head --lines=20 en_vert.txt\n",
        "!wc en_vert.txt\n",
        "# !head --lines=20 en1984_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7stVR-G1rFat"
      },
      "source": [
        "# !./treetagger/cmd/tree-tagger-english humanrights02.txt >humanrights02_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf0ZClfLrZd3"
      },
      "source": [
        "# !head --lines=20 humanrights02_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting a column needed for further processing (lemmas or other)"
      ],
      "metadata": {
        "id": "0UcigaSq2Wjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# some examples:\n",
        "\n",
        "## selecting column 3\n",
        "# awk -F '\\t' '(NF==3){print $3}' < covid1_l.txt >covid1_l_col3.txt\n",
        "\n",
        "## selects column 1\n",
        "# awk -F '\\t' '(NF==3){print $1}' < covid1_l.txt >covid1_l_col1.txt\n",
        "\n",
        "## selecting column 1, printing in one line, without line break after each word\n",
        "# awk -F '\\t' '(NF==3){printf \"%s \", $1}' < covid1_l.txt >covid1_lc1.txt\n",
        "\n",
        "## break at 1000 words, and start a new line (for word vectors)\n",
        "# awk -F '\\t' '(NF==3){printf \"%s \", $1; if(FNR % 10000 == 0){printf \"\\n\"}}' < covid1_l.txt >covid1_lc1.txt\n"
      ],
      "metadata": {
        "id": "wUjzXX_X2VZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## German and Georgian"
      ],
      "metadata": {
        "id": "p6psGNHaFr2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "wget https://heibox.uni-heidelberg.de/f/ec8226edebb64a359407/?dl=1\n",
        "mv index.html?dl=1 /content/treetagger/lib/german-utf8.par\n",
        "wget https://heibox.uni-heidelberg.de/f/9183090d2bdb41e09055/?dl=1\n",
        "mv index.html?dl=1 /content/treetagger/lib/georgian.par\n",
        "wget https://heibox.uni-heidelberg.de/f/a727b8b955da4ee19197/?dl=1\n",
        "mv index.html?dl=1 /content/treetagger/cmd/tree-tagger-english2\n",
        "wget https://heibox.uni-heidelberg.de/f/9cafab0509d64ed1ac4b/?dl=1\n",
        "mv index.html?dl=1 /content/treetagger/cmd/tree-tagger-georgian2\n",
        "wget https://heibox.uni-heidelberg.de/f/acb9b8a2fa4f40e08f8a/?dl=1\n",
        "mv index.html?dl=1 /content/treetagger/cmd/tree-tagger-german2"
      ],
      "metadata": {
        "id": "o0UrOkMxFyA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !chmod 755 /usr/local/bin/<FILE>\n",
        "!chmod 755 /content/treetagger/cmd/tree-tagger-english2\n",
        "!chmod 755 /content/treetagger/cmd/tree-tagger-georgian2\n",
        "!chmod 755 /content/treetagger/cmd/tree-tagger-german2"
      ],
      "metadata": {
        "id": "7FmpiMUEK7Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "wget https://heibox.uni-heidelberg.de/f/ea06aa47fe2d49959a62/?dl=1\n",
        "mv index.html?dl=1 go1984de.txt\n",
        "wget https://heibox.uni-heidelberg.de/f/318b32556cdc44d38238/?dl=1\n",
        "mv index.html?dl=1 go1984ka.txt"
      ],
      "metadata": {
        "id": "Kzq3_bHsJlBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./treetagger/cmd/tree-tagger-english2 en1984.txt >en1984_2_vert.txt\n",
        "!./treetagger/cmd/tree-tagger-german2 go1984de.txt >de1984_2_vert.txt\n",
        "!./treetagger/cmd/tree-tagger-georgian2 go1984ka.txt >ka1984_2_vert.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocjc-WbYKER9",
        "outputId": "0c23551e-38f8-426a-e726-8ae96b4fa6c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\treading parameters ...\n",
            "\ttagging ...\n",
            "121000\t finished.\n",
            "\treading parameters ...\n",
            "\ttagging ...\n",
            "120000\t finished.\n",
            "\treading parameters ...\n",
            "\ttagging ...\n",
            "85000\t finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC5cBgvas4vQ"
      },
      "source": [
        "## Armenian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW7HUG3TQzjU"
      },
      "source": [
        "# installing Armenian morphological analyser\n",
        "!git clone https://github.com/timarkh/uniparser-grammar-eastern-armenian"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgrVLqTTStuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bb1ec06-1fb0-4b33-caed-68ec6f930cf1"
      },
      "source": [
        "# Python classes\n",
        "!pip3 install uniparser-eastern-armenian"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uniparser-eastern-armenian\n",
            "  Downloading uniparser_eastern_armenian-2.1.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 4.0 MB/s \n",
            "\u001b[?25hCollecting uniparser-morph>=2.2.0\n",
            "  Downloading uniparser_morph-2.4.3-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from uniparser-eastern-armenian) (5.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->uniparser-eastern-armenian) (3.6.0)\n",
            "Installing collected packages: uniparser-morph, uniparser-eastern-armenian\n",
            "Successfully installed uniparser-eastern-armenian-2.1.2 uniparser-morph-2.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bALlnO8gY4cF"
      },
      "source": [
        "# disambiguation\n",
        "!sudo apt-get install cg3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5-Y0JQES0oT"
      },
      "source": [
        "from uniparser_eastern_armenian import EasternArmenianAnalyzer\n",
        "a = EasternArmenianAnalyzer()\n",
        "analyses = a.analyze_words('Ձևաբանություն')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1gZH7s3XfMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2165f4fe-901f-42ba-e402-466566e854ff"
      },
      "source": [
        "for ana in analyses:\n",
        "    print(ana.wf, ana.lemma, ana.gramm, ana.gloss, ana.stem, ana.subwords, ana.wfGlossed, ana.otherData)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ձևաբանություն ձեւաբանություն N,inanim,sg,nom,nonposs morphology ձևաբանություն. [] ձևաբանություն [('trans_en', 'morphology')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqmYRwfBlbNo"
      },
      "source": [
        "dir(ana)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ddvunxGTXQf"
      },
      "source": [
        "analyses = a.analyze_words([['և'], ['Ես', 'սիրում', 'եմ', 'քեզ', ':']],\n",
        "                           format='xml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuOyUBXmTbep"
      },
      "source": [
        "for ana in analyses:\n",
        "    print(str(ana))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWxToCMSTyL6"
      },
      "source": [
        "analyses = a.analyze_words(['Ձևաբանություն', [['և'], ['Ես', 'սիրում', 'եմ', 'քեզ', ':']]],\n",
        "                           format='json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxEQfFZvT1KM"
      },
      "source": [
        "for ana in analyses:\n",
        "    print(str(ana))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWNEo_RwUcSB"
      },
      "source": [
        "# analysis with disambiguation\n",
        "# analyses = a.analyze_words(['Ես', 'սիրում', 'եմ', 'քեզ'], disambiguate=True)\n",
        "#   \n",
        "analyses = a.analyze_words(['Դու', 'գալիս', 'ես'], disambiguate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRb9dCQoUdJc"
      },
      "source": [
        "for ana in analyses:\n",
        "    # print(wfo.wf, wfo.lemma, wfo.gramm, wfo.gloss)\n",
        "    # for wfo in ana[0:1]:\n",
        "    for wfo in ana:\n",
        "        print(wfo.wf, wfo.lemma, wfo.gramm, wfo.gloss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vzlcQSQlw55"
      },
      "source": [
        "print(type(wfo))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0P_zV02ZxQ8"
      },
      "source": [
        "dir(wfo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzINXeL7s9EL"
      },
      "source": [
        "# downloading and analysing texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJzA4Fg9tCaH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4947fb16-91a4-46ea-dcdc-3cea28499b05"
      },
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/e0bfae444a5a4c76957b/?dl=1\n",
        "!mv index.html?dl=1 hy1984.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-14 12:35:39--  https://heibox.uni-heidelberg.de/f/e0bfae444a5a4c76957b/?dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/0c8f0b6d-495a-442b-86c7-9bdd1ac50667/go1984hy.txt [following]\n",
            "--2021-12-14 12:35:40--  https://heibox.uni-heidelberg.de/seafhttp/files/0c8f0b6d-495a-442b-86c7-9bdd1ac50667/go1984hy.txt\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 540579 (528K) [text/plain]\n",
            "Saving to: ‘index.html?dl=1’\n",
            "\n",
            "index.html?dl=1     100%[===================>] 527.91K   423KB/s    in 1.2s    \n",
            "\n",
            "2021-12-14 12:35:42 (423 KB/s) - ‘index.html?dl=1’ saved [540579/540579]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOXdvc_9uv0J"
      },
      "source": [
        "FInText = open('hy1984.txt','r')\n",
        "FOutText = open('hy1984_vert.txt','w')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdxZiI7ZyLGW"
      },
      "source": [
        "for SLine in FInText:\n",
        "    SLine = SLine.strip()\n",
        "    # ListOfWords = re.split('[ ,\\.:;\\!\\(\\)\\\"\\[\\]՞՝«»\\-\\—՝։\\։]+', SLine) # tokenize: split on white spaces and punctuation\n",
        "    prefix_re = re.compile(r'''^[~։:,`´.՛՝»«\\/\\[\\(\\)\"']''')\n",
        "    suffix_re = re.compile(r'''[~։:,`´.՛՝»«\\/\\]\\)\\(\"']$''')\n",
        "    infix_re = re.compile(r'''[:։,`´.՛՝»«\\/-]''')\n",
        "\n",
        "    lehrz = re.compile(r'''^[~։:,`´.՛՝»«\\/\\[\\(\\)\"']|[:։,`´.՛՝»«\\/\\- ]|[~։:,`´.՛՝»«\\/\\]\\)\\(\"']$''')\n",
        "    ListOfWords = re.split(lehrz, SLine)\n",
        "\n",
        "    # ListOfWords = re.split('[ ,\\.:;\\!\\(\\)\\\"\\[\\]՞՝«»\\-\\—՝։\\։]+', SLine) # tokenize: split on white spaces and punctuation\n",
        "\n",
        "    # if len(ListOfWords) > 0: FOutText.write(str(ListOfWords) + '\\n')\n",
        "    analyses = a.analyze_words(ListOfWords, disambiguate=False)\n",
        "    FOutText.write('<p>\\n')\n",
        "    for ana in analyses:\n",
        "        # for wfo in ana:\n",
        "        # how to type all variants + disambiguate ?\n",
        "        wfo = ana[0]\n",
        "        FOutText.write(wfo.wf + '\\t' + wfo.gramm + '\\t' + wfo.lemma + '\\t' + wfo.gloss + '\\n')\n",
        "        #    FOutText.write(wfo.wf + '\\t' + wfo.gramm + '\\t' + wfo.lemma + '\\t' + wfo.gloss + '\\n')\n",
        "    FOutText.write('</p>\\n')\n",
        "FOutText.flush()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}