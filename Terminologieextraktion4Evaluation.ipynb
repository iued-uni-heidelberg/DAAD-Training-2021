{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Terminologieextraktion4Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN2CxVCMMQ/gTRmXaVZ+IWp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/DAAD-Training-2021/blob/main/Terminologieextraktion4Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN9DTw823QDH"
      },
      "source": [
        "# Evaluation of the terminology extraction results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6K-G2fFLE-4"
      },
      "source": [
        "Purpose: evaluating the tradeoff between precision and recall for different extraction methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F2EV7qc3fF3",
        "outputId": "bcebacbc-8130-4bb5-9cea-e97ef2e47250"
      },
      "source": [
        "# Stage 0: Preparing Gold standard: Reading / extracting information from gold standard: creating a list of annotated terms\n",
        "!wget https://heibox.uni-heidelberg.de/f/ae1110c4f9ad42b9a3d5/?dl=1\n",
        "!mv index.html?dl=1 BGH1_s00Astghik.txt\n",
        "!wget https://heibox.uni-heidelberg.de/f/0c787f26123f49178639/?dl=1\n",
        "!mv index.html?dl=1 BGH1_s00Hayk.txt\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-24 06:08:05--  https://heibox.uni-heidelberg.de/f/ae1110c4f9ad42b9a3d5/?dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/05191e8f-65bd-4c3e-b062-a7be55865294/BGH1_Astghik.txt [following]\n",
            "--2021-10-24 06:08:06--  https://heibox.uni-heidelberg.de/seafhttp/files/05191e8f-65bd-4c3e-b062-a7be55865294/BGH1_Astghik.txt\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 369792 (361K) [text/plain]\n",
            "Saving to: ‘index.html?dl=1’\n",
            "\n",
            "index.html?dl=1     100%[===================>] 361.12K   338KB/s    in 1.1s    \n",
            "\n",
            "2021-10-24 06:08:07 (338 KB/s) - ‘index.html?dl=1’ saved [369792/369792]\n",
            "\n",
            "--2021-10-24 06:08:07--  https://heibox.uni-heidelberg.de/f/0c787f26123f49178639/?dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/514642f8-8159-425f-9a82-6f437ad04252/BGH2_Hayk.txt [following]\n",
            "--2021-10-24 06:08:08--  https://heibox.uni-heidelberg.de/seafhttp/files/514642f8-8159-425f-9a82-6f437ad04252/BGH2_Hayk.txt\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 411864 (402K) [text/plain]\n",
            "Saving to: ‘index.html?dl=1’\n",
            "\n",
            "index.html?dl=1     100%[===================>] 402.21K   390KB/s    in 1.0s    \n",
            "\n",
            "2021-10-24 06:08:09 (390 KB/s) - ‘index.html?dl=1’ saved [411864/411864]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI2bPn1R-k8k"
      },
      "source": [
        "!cat BGH1_s00Astghik.txt BGH1_s00Hayk.txt >BGH1_s00GoldStandard.txt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM66Xi9-4lSs"
      },
      "source": [
        "FInput = open('BGH1_s00GoldStandard.txt', 'r')\n",
        "FOutput = open('BGH1_s00GoldS_Terms.txt', 'w')\n",
        "# for statistical purposes - separately single and multiword terms\n",
        "FOutputDict1w = open('BGH1_s00GoldS_D1w.txt', 'w')\n",
        "FOutputDictMWE = open('BGH1_s00GoldS_DMWE.txt', 'w')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvajJguDHp9I"
      },
      "source": [
        "def printDictionary(DictionaryFrq, FOut, Rev = True):\n",
        "    for Word, Frq in sorted( DictionaryFrq.items() , key=lambda x: x[1], reverse=Rev):\n",
        "        FOut.write(Word + '\\t' + str(Frq) + '\\n')\n",
        "    return"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGp9Uqli568A"
      },
      "source": [
        "import re, os, sys\n",
        "LGSTerms = [] # gold standard terms\n",
        "DGS1w = {} # dictionary of single words\n",
        "DGSMWE = {} # dictionary of mwes\n",
        "IGS1w = 0 # number of annotated tokens of single words\n",
        "IGSMWE = 0 # number of annotated tokens of multiwords\n",
        "for SLine in FInput:\n",
        "    LAnnotatedTermsInLine = re.findall('<<([^><]+)>>', SLine)\n",
        "    LGSTerms.extend(LAnnotatedTermsInLine)\n",
        "\n",
        "for GSTerm in LGSTerms:\n",
        "    GSTerm = GSTerm.strip()\n",
        "    GSTerm = re.sub(' +', ' ', GSTerm)\n",
        "    if re.search(' ', GSTerm):\n",
        "        IGSMWE += 1\n",
        "        try: DGSMWE[GSTerm] += 1\n",
        "        except: DGSMWE[GSTerm] = 1\n",
        "    else:\n",
        "        IGS1w += 1\n",
        "        try: DGS1w[GSTerm] +=1\n",
        "        except: DGS1w[GSTerm] = 1\n",
        "\n",
        "    FOutput.write(GSTerm + '\\n')\n",
        "\n",
        "FOutputDictMWE.write('# Number of tokens: ' + str(IGSMWE) + '\\n')\n",
        "FOutputDict1w.write('# Number of tokens: ' + str(IGS1w) + '\\n')\n",
        "\n",
        "printDictionary(DGSMWE, FOutputDictMWE)\n",
        "printDictionary(DGS1w, FOutputDict1w)\n",
        "\n",
        "FOutputDictMWE.flush()\n",
        "FOutputDictMWE.close()\n",
        "FOutputDict1w.flush()\n",
        "FOutputDict1w.close()\n",
        "\n",
        "FOutput.flush()\n",
        "FOutput.close()\n",
        "\n",
        "FInput.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l4C6taZ3MST",
        "outputId": "903d9fe4-aa5a-456c-da96-104c7a46f502"
      },
      "source": [
        "# Stage 1: Reading test data - Possible Terms (extracted automatically): reading the text files of single and multiword terms, recording ranks\n",
        "# single words candidates\n",
        "!wget https://heibox.uni-heidelberg.de/f/a9171080790f4932b7b1/?dl=1\n",
        "!mv index.html?dl=1 BGH1_s00term1w.txt\n",
        "\n",
        "# multiword candidates\n",
        "!wget https://heibox.uni-heidelberg.de/f/2488701205e34e4683b1/?dl=1\n",
        "!mv index.html?dl=1 BGH1_s00termMWE.txt\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-24 06:09:51--  https://heibox.uni-heidelberg.de/f/a9171080790f4932b7b1/?dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/850504a2-25b4-4d5f-908d-6b622f469177/BGH_term1w.txt [following]\n",
            "--2021-10-24 06:09:52--  https://heibox.uni-heidelberg.de/seafhttp/files/850504a2-25b4-4d5f-908d-6b622f469177/BGH_term1w.txt\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8954371 (8.5M) [text/plain]\n",
            "Saving to: ‘index.html?dl=1’\n",
            "\n",
            "index.html?dl=1     100%[===================>]   8.54M  5.21MB/s    in 1.6s    \n",
            "\n",
            "2021-10-24 06:09:54 (5.21 MB/s) - ‘index.html?dl=1’ saved [8954371/8954371]\n",
            "\n",
            "--2021-10-24 06:09:54--  https://heibox.uni-heidelberg.de/f/2488701205e34e4683b1/?dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/95365b0d-0d42-42b9-ac6c-927eb5896044/BGH_termMWE.txt [following]\n",
            "--2021-10-24 06:09:54--  https://heibox.uni-heidelberg.de/seafhttp/files/95365b0d-0d42-42b9-ac6c-927eb5896044/BGH_termMWE.txt\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 78612600 (75M) [text/plain]\n",
            "Saving to: ‘index.html?dl=1’\n",
            "\n",
            "index.html?dl=1     100%[===================>]  74.97M  18.5MB/s    in 5.2s    \n",
            "\n",
            "2021-10-24 06:10:00 (14.5 MB/s) - ‘index.html?dl=1’ saved [78612600/78612600]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSgfBR0QMmQ5"
      },
      "source": [
        "FInputPossibleTerms1w = open('BGH1_s00term1w.txt', 'r')\n",
        "FInputPossibleTermsMWE = open('BGH1_s00termMWE.txt', 'r')\n",
        "\n",
        "FOutputResults1w = open('BGH1_s01term1w_res.txt', 'w')\n",
        "FOutputResultsMWE = open('BGH1_s01termMWE_res.txt', 'w')\n",
        "# FOutputResults = open('BGH1_term_s01res.txt', 'w')\n",
        "FOutputDebug = open('BGH1_s01term_debug.txt', 'w')\n",
        "\n",
        "\n",
        "FOutputResults1wFOUND = open('BGH1_s02term1w_resY.txt', 'w')\n",
        "FOutputResultsMWEFOUND = open('BGH1_s02termMWE_resY.txt', 'w')\n",
        "\n",
        "FOutputResults1wMISSING = open('BGH1_s02term1w_resN.txt', 'w')\n",
        "FOutputResultsMWEMISSING = open('BGH1_s02termMWE_resN.txt', 'w')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMih63KTQhMv"
      },
      "source": [
        "import re, os, sys\n",
        "def readDict2rank(FIN):\n",
        "    '''\n",
        "    reading a frequency dictionary from a file\n",
        "    '''\n",
        "    DTermRanks = {}\n",
        "    i = 0\n",
        "    IRank = 0\n",
        "    IPrevFrq = 0\n",
        "    SumRanks = 0\n",
        "    for SLine in FIN:\n",
        "        if re.match('#', SLine): continue # skipping comments\n",
        "        SLine = SLine.strip()\n",
        "        LLine = re.split('\\t', SLine)\n",
        "        try:\n",
        "            Word = LLine[0]\n",
        "            Frq = int(LLine[1])\n",
        "        except:\n",
        "            continue\n",
        "        if Word in DTermRanks: FOutputDebug.write(SLine + '\\n') # checking for duplicates, there should not be any\n",
        "        i+=1\n",
        "        if IPrevFrq != Frq: IRank = i # rank is the number of the highest ranking element of the same frequency group\n",
        "        IPrevFrq = Frq\n",
        "        \n",
        "        DTermRanks[Word] = IRank\n",
        "        SumRanks += IRank\n",
        "\n",
        "    AAveRank = SumRanks / i\n",
        "    print(f'MaxRank = {IRank}\\nAve Rank = {AAveRank}\\n')\n",
        "    return DTermRanks, AAveRank"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C09OzcAeWATo",
        "outputId": "7e7e9b1a-0faf-4033-9641-e6d86fbbf7eb"
      },
      "source": [
        "D1W, AveRank1w = readDict2rank(FInputPossibleTerms1w)\n",
        "DMWE, AveRankMWE = readDict2rank(FInputPossibleTermsMWE)\n",
        "\n",
        "\n",
        "# testing that ranks were converted successfully:\n",
        "printDictionary(D1W, FOutputResults1w, Rev = False)\n",
        "printDictionary(DMWE, FOutputResultsMWE, Rev = False)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MaxRank = 261813\n",
            "Ave Rank = 182223.02101087398\n",
            "\n",
            "MaxRank = 709822\n",
            "Ave Rank = 582409.8984508096\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZhm1w1laTCq",
        "outputId": "6d9021c1-161d-4d8c-f3fa-b11c6c5da033"
      },
      "source": [
        "# Stage 2: calculating recall for dictionaries that were read from gold standard\n",
        "\n",
        "def computeRecallOnAnnotation(DGS1w, D1W, FOutputResultsFOUND, FOutputResultsMISSING, SortBy = 0, Rev = False, ):\n",
        "\n",
        "    print('Total annotated in Gold Standard: ' + str(len(DGS1w.items())))\n",
        "    IFound = 0\n",
        "    IMissing = 0\n",
        "    SumFoundRanks = 0\n",
        "\n",
        "    for Word, Frq in sorted(DGS1w.items(),  key=lambda x: x[SortBy], reverse=Rev):\n",
        "        if Word in D1W:\n",
        "            IFound += 1\n",
        "            SumFoundRanks += D1W[Word] # add rank, to calculate average\n",
        "            FOutputResultsFOUND.write(Word + '\\t' + str(Frq) + '\\t' + str(D1W[Word]) + '\\n') # record/calculate average rank, etc.\n",
        "        else:\n",
        "            IMissing += 1\n",
        "            FOutputResultsMISSING.write(Word + '\\t' + str(Frq) + '\\n') # record/calculate average rank, etc.\n",
        "\n",
        "    print(f'Found: {IFound}')\n",
        "    print(f'Missing: {IMissing}')\n",
        "    ARecall = IFound / len(DGS1w.items())\n",
        "    print(f'Recall: {ARecall}')\n",
        "    AAverageFoundRanks = SumFoundRanks / IFound\n",
        "    print(f'Ave Found Ranks: {AAverageFoundRanks} \\n')\n",
        "\n",
        "    return ARecall, AAverageFoundRanks\n",
        "\n",
        "\n",
        "ARecall_1w, AAverageFoundRanks1w = computeRecallOnAnnotation(DGS1w, D1W, FOutputResults1wFOUND, FOutputResults1wMISSING, SortBy = 0, Rev = False)\n",
        "ARecall_MWE, AAverageFoundRanksMWE = computeRecallOnAnnotation(DGSMWE, DMWE, FOutputResultsMWEFOUND, FOutputResultsMWEMISSING, SortBy = 0, Rev = False)\n",
        "\n",
        "AAboveAve1w = AAverageFoundRanks1w / AveRank1w\n",
        "AAboveAveMWE = AAverageFoundRanksMWE / AveRankMWE\n",
        "\n",
        "print(f'\\nAboveAve1w: {AAboveAve1w}\\nAboveAveMWE: {AAboveAveMWE}')\n",
        "\n",
        "FOutputResults1wFOUND.flush()\n",
        "FOutputResults1wFOUND.close()\n",
        "FOutputResults1wMISSING.flush()\n",
        "FOutputResults1wMISSING.close()\n",
        "\n",
        "FOutputResultsMWEFOUND.flush()\n",
        "FOutputResultsMWEFOUND.close()\n",
        "FOutputResultsMWEMISSING.flush()\n",
        "FOutputResultsMWEMISSING.close()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total annotated in Gold Standard: 431\n",
            "Found: 383\n",
            "Missing: 48\n",
            "Recall: 0.888631090487239\n",
            "Ave Found Ranks: 24651.738903394256 \n",
            "\n",
            "Total annotated in Gold Standard: 156\n",
            "Found: 50\n",
            "Missing: 106\n",
            "Recall: 0.32051282051282054\n",
            "Ave Found Ranks: 148709.12 \n",
            "\n",
            "\n",
            "AboveAve1w: 0.13528333997888878\n",
            "AboveAveMWE: 0.25533412188831467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNxwjtcQElQA"
      },
      "source": [
        "# Stage03: preparing data for calculating precision and recall on the space of all possible MWEs (overlapping)\n",
        "FInput = open('BGH1_s00GoldStandard.txt', 'r')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy2nfTy5zsmR"
      },
      "source": [
        "# tokenizing gold standard\n",
        "'''\n",
        "The idea is to tokenise the gold standard (from Stage 0), and to generate all possible MWEs for each string / pargraph\n",
        "    then we can test what is the coverage (non-overlapping) or precision (overlapping)\n",
        "    or: we create a dictionary of potential single and MWE strings and check what has been identified ?\n",
        "    or: comparing with 'oracle': known annotations are run as a point of comparision on the space; and we establish relations, i.e., the amount of over-generation\n",
        "\n",
        "    tasks: \n",
        "        3a: create the \"all possible strings\" space from gold standard text\n",
        "        3b: intersect 3a results with corpus list of extracted MWEs >> generate \"extracted from gold standar\" dictionary\n",
        "        3c: intersect human annotation in gold standard with 3a >> generate \"correct in gold standard\" dictionary\n",
        "        3d: intersect 3b and 3c, >> correctly extracted\n",
        "        3e: calculate 3d/3b = precision\n",
        "            calculate 3d/3c = recall\n",
        "\n",
        "'''\n",
        "# 3a: processing gold standard: tokenizing\n",
        "import re, os, sys\n",
        "LLParTokens = [] # List of paragraphs, each represented as a list of tokens\n",
        "for SLine in FInput:\n",
        "    SLine.strip()\n",
        "    # separate punctuation\n",
        "    SLine = re.sub(r'(,\\.;:\\-\\!\\?\\(\\)\\[\\]\\“\\\")', r' \\1 ', SLine)\n",
        "    # remove annotation\n",
        "    SLine = re.sub('[<>]+', ' ', SLine)\n",
        "    SLine = re.sub(' +', ' ', SLine)\n",
        "    LLine = re.split(' ', SLine)\n",
        "    LLParTokens.append(LLine)\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu-gLBDVsOlX"
      },
      "source": [
        "FOutputA1w = open('BGH1_s03A1w_res.txt', 'w')\n",
        "FOutputAMWE = open('BGH1_s03AMWE_res.txt', 'w')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M5s2o9u5nOA"
      },
      "source": [
        "# generating candidate MWEs for cheking if / when they have been identified as terms\n",
        "# algorithm from Terminologieextraktion3 notebook\n",
        "# 3a: creating space of all possible overlapping MWEs in gold standard\n",
        "import re, os, sys\n",
        "def tokens2candMWEs(LWords):\n",
        "    '''\n",
        "    convert a list of tokens into a list of all possible MWEs (works for each paragraph)\n",
        "    '''\n",
        "    LLCandidates = [] # lists - tokenised results\n",
        "    LSCandidates = [] # strings - joint results\n",
        "    for klen in range(len(LWords)): # lengths of candidate lists\n",
        "        klength = klen+1 # true length: for 0 it is le = 1\n",
        "        # print(f'klen:{klength};')\n",
        "        for i in range(len(LWords) - klen): # positions where candidates start\n",
        "            # print(f'i:{i};')\n",
        "            LCandidate = LWords[i:i+klength]\n",
        "            SCandidate = ' '.join(LCandidate)\n",
        "            LLCandidates.append(LCandidate)\n",
        "            LSCandidates.append(SCandidate)\n",
        "        \n",
        "    return LLCandidates, LSCandidates\n",
        "\n",
        "# creating 3a dictionaries for 1w and MWEs\n",
        "DA_1W = {} # dictionary of 1-word candidates from the gold standard text (to be tested)\n",
        "DA_MWE = {} # dictionary of MWE candidates from the gold standard text (to be tested)\n",
        "\n",
        "for LTokens in LLParTokens: # for each paragraph\n",
        "    LLCandidates, LSCandidates = tokens2candMWEs(LTokens)\n",
        "    for SCandidate in LSCandidates:\n",
        "        if re.search(' ', SCandidate):\n",
        "            try:\n",
        "                DA_1W[SCandidate] += 1\n",
        "            except:\n",
        "                DA_1W[SCandidate] = 1\n",
        "        else:\n",
        "            try:\n",
        "                DA_MWE[SCandidate] += 1\n",
        "            except:\n",
        "                DA_MWE[SCandidate] = 1          \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpwN4SOgszrp"
      },
      "source": [
        "printDictionary(DA_1W, FOutputA1w, Rev = True)\n",
        "printDictionary(DA_MWE, FOutputAMWE, Rev = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhcZHB49qPnN"
      },
      "source": [
        "# creating output files for B\n",
        "FOutputFOUND1wBinA = open('BGH1_s03BinA1w_resY.txt', 'w')\n",
        "FOutputMISSING1wBinA = open('BGH1_s03BinA_resN.txt', 'w')\n",
        "FOutputFOUNDMWEsBinA = open('BGH1_s03BinAMWE_resY.txt', 'w')\n",
        "FOutputMISSINGMWEsBinA = open('BGH1_s03BinAMWE_resN.txt', 'w')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB1CfKTjAqbZ"
      },
      "source": [
        "# calculating precision on types (not tokens)\n",
        "\n",
        "# creating 3B dictionary: searching \n",
        "DB_1W = {}\n",
        "DB_MWE = {}\n",
        "\n",
        "# one-directional comparison of two dictionaries; arguments: DGoldStandard (smaller) DTest (larger), file: GS items found in DTest; GS items missing from DText...\n",
        "def countIntersectDictionaries(DGS, DTest, FOutputPrecFOUND, FOutputPrecMISSING, SortBy = 0, Ref = False):\n",
        "    '''\n",
        "    general function: intersect dictionaries, return new intersection dictionaries, record \"in\" and \"out\" expressions\n",
        "    \n",
        "    3b: intersecting All possible MWEs in GS list with the \"Extracted\" list\n",
        "    DA (smaller and going over each element) with D1W / DMWE lists \n",
        "    '''\n",
        "\n",
        "    print('Total len of Gold Standard: ' + str(len(DGS.items())))\n",
        "    IFound = 0\n",
        "    IMissing = 0\n",
        "    SumFoundRanks = 0\n",
        "    DFound = {} # intersection dictionary\n",
        "\n",
        "    for Word, Frq in sorted(DGS.items(),  key=lambda x: x[SortBy], reverse=Rev):\n",
        "        if Word in DTest:\n",
        "            IFound += 1\n",
        "            try: # normally will not fire: if this word already exists with some rank, calculate the average of a new and old rank\n",
        "                r0 = DFound[Word]\n",
        "                r1 = DTest[Word]\n",
        "                r = (r0+r1)/2\n",
        "                DFound[Word] = r\n",
        "            except: # normal route: find the rank of the word in the dictionary\n",
        "                DFound[Word] = DTest[Word]\n",
        "\n",
        "            SumFoundRanks += DTest[Word] # add rank, to calculate average\n",
        "            FOutputPrecFOUND.write(Word + '\\t' + str(Frq) + '\\t' + str(D1W[Word]) + '\\n') # record/calculate average rank, etc.\n",
        "        else:\n",
        "            IMissing += 1\n",
        "            FOutputPrecMISSING.write(Word + '\\t' + str(Frq) + '\\n') # record/calculate average rank, etc.\n",
        "\n",
        "    print(f'Found: {IFound}')\n",
        "    print(f'Missing: {IMissing}')\n",
        "    ARecall = IFound / len(DGS.items())\n",
        "    print(f'Found2LenGS: {ARecall}')\n",
        "    AAverageFoundRanks = SumFoundRanks / IFound\n",
        "    print(f'Ave Found Ranks: {AAverageFoundRanks} \\n')\n",
        "\n",
        "    return ARecall, AAverageFoundRanks, DFound\n",
        "\n",
        "\n",
        "AFound1wBinA, AAverageFoundRanks1wBinA, DB_1W = countIntersectDictionaries(DA_1W, D1W, FOutputFOUND1wBinA, FOutputMISSING1wBinA, SortBy = 0, Ref = False)\n",
        "AFoundMWEBinA, AAverageFoundRanksMWEBinA, DB_MWE = countIntersectDictionaries(DA_MWE, DMWE, FOutputFOUNDMWEsBinA, FOutputMISSINGMWEsBinA, SortBy = 0, Ref = False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U75vzNnktKCX"
      },
      "source": [
        "# creating output files for C (normally should be 100% overlap, this is just a check of the general approach)\n",
        "FOutputFOUND1wCinA = open('BGH1_s03CinA1w_resY.txt', 'w')\n",
        "FOutputMISSING1wCinA = open('BGH1_s03CinA_resN.txt', 'w')\n",
        "FOutputFOUNDMWEsCinA = open('BGH1_s03CinAMWE_resY.txt', 'w')\n",
        "FOutputMISSINGMWEsCinA = open('BGH1_s03CinAMWE_resN.txt', 'w')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k2qI50StpwQ"
      },
      "source": [
        "DC_1W = {}\n",
        "DC_MWE = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NggOPsXgtgWV"
      },
      "source": [
        "AFound1wCinA, AAverageFoundRanks1wCinA, DC_1W = countIntersectDictionaries(DA_1W, D1W, FOutputFOUND1wBinA, FOutputMISSING1wBinA, SortBy = 0, Ref = False)\n",
        "AFoundMWECinA, AAverageFoundRanksMWECinA, DC_MWE = countIntersectDictionaries(DA_MWE, DMWE, FOutputFOUNDMWEsBinA, FOutputMISSINGMWEsBinA, SortBy = 0, Ref = False)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}